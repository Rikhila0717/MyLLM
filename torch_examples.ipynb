{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T02:27:27.967304Z",
     "start_time": "2025-07-18T02:27:26.993419Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.version import cuda"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T02:27:51.381396Z",
     "start_time": "2025-07-18T02:27:51.373211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "randint = torch.randint(-100, 100, (6,))\n",
    "randint"
   ],
   "id": "566a4eab3603b8ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -31,   61,   35,  -91,  -23, -100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T02:29:19.636824Z",
     "start_time": "2025-07-18T02:29:19.617087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor(([0.1,0.2], [0.3,0.4], [0.5,0.6]))\n",
    "tensor"
   ],
   "id": "d3ef2e1209f589e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000],\n",
       "        [0.3000, 0.4000],\n",
       "        [0.5000, 0.6000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T02:30:17.557995Z",
     "start_time": "2025-07-18T02:30:17.550945Z"
    }
   },
   "cell_type": "code",
   "source": [
    " zeros = torch.zeros(2,3)\n",
    " zeros"
   ],
   "id": "34ff566eec45f6e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T02:30:38.876897Z",
     "start_time": "2025-07-18T02:30:38.866429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones"
   ],
   "id": "23ca22c9121fa470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T02:31:13.655542Z",
     "start_time": "2025-07-18T02:31:13.650590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = torch.empty(2,3)\n",
    "input"
   ],
   "id": "eb8a6fb78388b2c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:02:01.654921Z",
     "start_time": "2025-07-18T03:02:01.643921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arange = torch.arange(5)\n",
    "arange"
   ],
   "id": "133413228865f17f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:03:52.729225Z",
     "start_time": "2025-07-18T03:03:52.720833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linspace = torch.linspace(3,10,steps=5)\n",
    "linspace"
   ],
   "id": "e0b7b33297fef725",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:08:14.432206Z",
     "start_time": "2025-07-18T03:08:14.421958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logspace =  torch.logspace(start=-10,end=10,steps=5)\n",
    "logspace"
   ],
   "id": "20df4959055e15c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:09:07.169759Z",
     "start_time": "2025-07-18T03:09:07.157856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eye=torch.eye(5)\n",
    "eye"
   ],
   "id": "c7a40562b03b00b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:11:05.010490Z",
     "start_time": "2025-07-18T03:11:05.000183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.empty((2,3),dtype=torch.int64)\n",
    "empty_like = torch.empty_like(a)\n",
    "empty_like"
   ],
   "id": "72bd58e08fd63a75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:22:17.393308Z",
     "start_time": "2025-07-18T03:22:17.387035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Cuda's alternative in MAC is Metal Performance Shaders (MPS) from the library Metal, which can leverage in-built MAC GPUs instead of using an external GPU or Cuda'''\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ],
   "id": "68e5356343db16f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:24:52.641229Z",
     "start_time": "2025-07-18T03:24:52.634069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "zeros = torch.zeros(2,3)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time-start_time\n",
    "print(f\"elapsed time:{elapsed_time:.8f}\")"
   ],
   "id": "51d0652dd6b5f534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:0.00074697\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T04:01:46.688409Z",
     "start_time": "2025-07-18T04:01:43.430823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch_rand_1 = torch.rand(100,100, 100, 100).to(device)\n",
    "torch_rand_2 = torch.rand(100,100, 100, 100).to(device)\n",
    "numpy_rand_1 = torch.rand(100,100, 100, 100)\n",
    "numpy_rand_2 = torch.rand(100,100,100,100)\n",
    "\n",
    "start_time = time.time()\n",
    "#multiply tensors in torch\n",
    "rand = torch_rand_1 @ torch_rand_2\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"elapsed time:{elapsed_time:.8f}\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "rand = np.multiply(numpy_rand_1, numpy_rand_2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"elapsed time:{elapsed_time:.8f}\")"
   ],
   "id": "640721edef2f9592",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:0.03003979\n",
      "elapsed time:0.27669907\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T18:54:26.710333Z",
     "start_time": "2025-07-21T18:54:26.704539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "probabilities = torch.tensor([0.1,0.9])\n",
    "#draw 5 samples from multinomial distribution\n",
    "\n",
    "samples = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "samples"
   ],
   "id": "5f4e211fa3a28623",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T18:56:38.512317Z",
     "start_time": "2025-07-21T18:56:38.494115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1,2,3,4])\n",
    "new_tensor = torch.cat((tensor, torch.tensor([5])),dim=0)\n",
    "new_tensor"
   ],
   "id": "f45d8410eccc9d23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T18:58:40.576597Z",
     "start_time": "2025-07-21T18:58:40.553880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = torch.tril(torch.ones(5,5))\n",
    "out\n",
    "'''\n",
    "Notice how every row builds up on the number of 1s. We can assume these 1s to be the history of the tokens predicted.\n",
    "This way, as we build up on predictions, we have more history to refer to.\n",
    "'''"
   ],
   "id": "f73e7f0217a7d78d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T18:58:58.907267Z",
     "start_time": "2025-07-21T18:58:58.888863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = torch.triu(torch.ones(5,5))\n",
    "out"
   ],
   "id": "4ea09d088ee35e2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T23:35:01.848861Z",
     "start_time": "2025-07-22T23:35:01.821982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#when you exponentiate this...\n",
    "out = torch.zeros(5,5).masked_fill(torch.tril(torch.ones(5,5))==0, float('-inf'))\n",
    "print(out)\n",
    "torch.exp(out)"
   ],
   "id": "e61f7a692abfa803",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T23:36:59.789562Z",
     "start_time": "2025-07-22T23:36:59.775268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = torch.zeros(2,3,4)\n",
    "print(input.shape)\n",
    "print(input)\n",
    "#swapping zeroth with the second entry\n",
    "output = input.transpose(0,2)\n",
    "print(output.shape)\n",
    "print(output)"
   ],
   "id": "61cedcb2308a4777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "torch.Size([4, 3, 2])\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T23:38:32.688150Z",
     "start_time": "2025-07-22T23:38:32.672206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([4,5,6])\n",
    "tensor3 = torch.tensor([7,8,9])\n",
    "#stack tensors along a new dimension - useful for batchsize hyperparameter\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "stacked_tensor"
   ],
   "id": "e4284be59cca41c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T18:15:10.493062Z",
     "start_time": "2025-07-24T18:15:10.458077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    " torch.nn is a module which has all the utilities and parameters that can be used to build and train a neural network more efficiently. Ex. Linear, Activations, Layers\n",
    "'''\n",
    "\n",
    "import torch.nn as nn\n",
    "sample = torch.tensor([10.,10.,10.])\n",
    "linear = nn.Linear(3,3,bias=False)\n",
    "print(linear(sample))\n",
    "\n",
    "'''\n",
    "Linear layer linearly transforms the inputs using randomly initialized weights.\n",
    "\n",
    "Y = X*(W^T) + Bias\n",
    "So it initializes the weights randomly, and performs matrix multiplication with the input features, resulting in the defined output size transformation.\n",
    "\n",
    "We can set our own weights using\n",
    "linear.weights.data = torch.tensor(\n",
    "    [0.5, 0.1, -0.3],\n",
    "    [0.2, 0.4,  0.7],\n",
    "    [-0.6, 0.8, 0.2]\n",
    ")\n",
    "\n",
    "why do we need to use a linear transformation of input?\n",
    "\n",
    "So we are basically looking to train our network to learn the best possible correlations between the\n",
    "importance of each input feature contributing to the output prediction.\n",
    "\n",
    "So Linear transformation is a way to scale, and mix up the input data in different ways, until we know the best way to utilize these inputs to predict the output.\n",
    "So the weights can be considered as the importance we give for each input feature.\n",
    "The dimensions of the weights matrix is generally [output_features, input_features] and the bias, if mentioned, is [output_features].\n",
    "\n",
    "During the training, we come up with the best weights to accurately determine the outputs.\n",
    "'''\n"
   ],
   "id": "c321f366f8e68eea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.3766,  2.4042, 11.1491], grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLinear layer linearly transforms the inputs using randomly initialized weights.\\n\\nY = X*(W^T) + Bias\\nSo it initializes the weights randomly, and performs matrix multiplication with the input features, resulting in the defined output size transformation.\\n\\nWe can set our own weights using\\nlinear.weights.data = torch.tensor(\\n    [0.5, 0.1, -0.3],\\n    [0.2, 0.4,  0.7],\\n    [-0.6, 0.8, 0.2]\\n)\\n\\nwhy do we need to use a linear transformation of input?\\n\\nSo we are basically looking to train our network to learn the best possible correlations between the\\nimportance of each input feature contributing to the output prediction.\\n\\nSo Linear transformation is a way to scale, and mix up the input data in different ways, until we know the best way to utilize these inputs to predict the output.\\nSo the weights can be considered as the importance we give for each input feature.\\nThe dimensions of the weights matrix is generally [output_features, input_features] and the bias, if mentioned, is [output_features].\\n\\nDuring the training, we come up with the best weights to accurately determine the outputs.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T18:22:24.497849Z",
     "start_time": "2025-07-24T18:22:24.477821Z"
    }
   },
   "cell_type": "code",
   "source": [
    " '''\n",
    " Softmax -\n",
    "\n",
    " if we apply softmax to [1,2,3] -\n",
    " exp_sum = exp(1)+exp(2)+exp(3)\n",
    " [exp(1)/exp_sum, exp(2)/exp_sum, exp(3)/exp_sum]\n",
    "\n",
    " Softmax basically converts a vector of raw scores (logits) into probabilities (as explained above).\n",
    " These are generally the probabilities associated with each class label.\n",
    " '''\n",
    " import torch.nn.functional as F\n",
    " tensor1 = torch.tensor([1.,2.,3.])\n",
    " softmax_out = F.softmax(tensor1, dim=0)\n",
    " softmax_out\n"
   ],
   "id": "850a1203345d1838",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T19:45:58.909658Z",
     "start_time": "2025-07-24T19:45:58.900807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "nn.Embedding layer - Embedding is a very important concept in NLP, where you associate a word, token or a character to a list of real-valued numbers as a vector representation of that word. This allows us to identify the semantic relations of these words/tokens/charactes in the vector space, based on the closeness.\n",
    "Imagine another dimension, where you map all these words with their associated vector representations. That dimension is where we have these \"vector embeddings\" of words.\n",
    "\n",
    "Since a computer can't technically understand natural language, embedding these words into the vector space using real-valued numbers allows them to identify the semantic connections of these words. This helps in performing various NLP tasks such as dialogue generation, sequence-to-sequence predictions.\n",
    "'''\n",
    "vocab_size = 10\n",
    "embedding_dim = 2\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "input_indices = torch.LongTensor([1,5])\n",
    "embedded_output = embedding(input_indices)\n",
    "print(embedded_output)\n",
    "print(embedded_output.shape)"
   ],
   "id": "20fcea4e30f30b06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9976,  0.6869],\n",
      "        [ 0.4539, -0.0964]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T19:41:36.420474Z",
     "start_time": "2025-07-31T19:41:36.397776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\"\"\"\n",
    "If we want to compute dot product of two matrices,\n",
    "they should adhere to a rule - the dimensions of the matrices should be of the format - lxm, mxn\n",
    "the resulting matrix will be of lxn\n",
    "\n",
    "Let matrix A be\n",
    "| 1,2 |\n",
    "| 3,4 |\n",
    "| 5,6 |\n",
    "\n",
    "Let matrix B be\n",
    "| 7  8   9  |\n",
    "| 10 11  12 |\n",
    "\n",
    "A@B = (1*7)+(2*10); (1*8)+(2*11); (1*9)+(2*12)\n",
    "      (3*7)+(4*10); (3*8)+(4*11); (3*9)+(4*12)\n",
    "      (5*7)+(6*10); (5*8)+(6*11); (5*9)+(6*12)\n",
    "\n",
    "    = | 27  30  33 |\n",
    "      | 61  68  75 |\n",
    "      | 95 106 117 |\n",
    "\"\"\"\n",
    "\n",
    "a = torch.tensor(([1,2],[3,4],[5,6]))\n",
    "b = torch.tensor(([7,8,9],[10,11,12]))\n",
    "print(a @ b)\n",
    "print(torch.matmul(a,b))"
   ],
   "id": "b4813fe584aa9b21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7190c70edbcdb77f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
